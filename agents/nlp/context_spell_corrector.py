import re
from collections import Counter, defaultdict
from typing import List, Dict, Tuple

try:
    from spellchecker import SpellChecker
    HAS_PYSPELLCHECKER = True
except ImportError:
    HAS_PYSPELLCHECKER = False

class ContextSpellCorrector:
    """
    Correcteur orthographique Hybride (True NLP).
    1. BibliothÃ©que Standard (pyspellchecker) pour vocabulaire large.
    2. N-Grams (Bigrams) pour le contexte mÃ©dical spÃ©cifique.
    """
    
    def __init__(self):
        self.vocab = Counter()
        self.bigrams = Counter()
        self.total_words = 0
        
        # Initialisation correcteur standard
        self.spell_checkers = {}
        if HAS_PYSPELLCHECKER:
            try:
                self.spell_checkers['en'] = SpellChecker(language='en')
                self.spell_checkers['en'].word_frequency.load_words(['arrhythmia', 'tachycardia', 'dyspnea'])
                
                self.spell_checkers['fr'] = SpellChecker(language='fr')
                self.spell_checkers['fr'].word_frequency.load_words(['coeur', 'tÃªte', 'ventre'])
            except Exception as e:
                print(f"âš ï¸ Erreur init corrections: {e}")
        self.total_words = 0
        
        # Mots mÃ©dicaux critiques (PrioritÃ© absolue)
        self.medical_priority = {
            'headache', 'stomachache', 'toothache', 'backache',
            'pain', 'ache', 'hurt', 'sore', 'fever',
            'heart', 'chest', 'stomach', 'belly', 'head', 'tooth', 'teeth',
            'throat', 'lung', 'arm', 'leg', 'foot', 'eye', 'ear',
            'nausea', 'vomiting', 'dizziness', 'bleeding'
        }
        
        # Mots Ã  NE PAS CORRIGER (Stopwords anglais courants)
        self.protected_words = {
            'i', 'a', 'an', 'am', 'is', 'are', 'was', 'were',
            'in', 'on', 'at', 'to', 'for', 'of', 'with', 'from',
            'the', 'this', 'that', 'these', 'those',
            'my', 'your', 'his', 'her', 'its', 'our', 'their',
            'and', 'but', 'or', 'so', 'if', 'when', 'where',
            'have', 'has', 'had', 'do', 'does', 'did',
            'he', 'she', 'it', 'we', 'they', 'you', 'me',
        }

    def train(self, texts: List[str]):
        """Apprend les probabilitÃ©s des mots et des contextes depuis le dataset"""
        print("   ğŸ“š EntraÃ®nement du correcteur contextuel (N-Grams)...")
        
        for text in texts:
            # Tokenization simple
            words = self._tokenize(text)
            self.vocab.update(words)
            self.total_words += len(words)
            
            # Construction des Bigrams (Mot prÃ©cÃ©dent -> Mot actuel)
            for i in range(len(words) - 1):
                bigram = (words[i], words[i+1])
                self.bigrams[bigram] += 1
                
        print(f"      âœ… Vocabulaire: {len(self.vocab)} mots")
        print(f"      âœ… Contextes appris: {len(self.bigrams)} bigrams")

    def correct_text(self, text: str, lang: str = 'en') -> Tuple[str, List[Dict]]:
        """Corrige le texte en utilisant le contexte + Pyspellchecker (Multi-langue)"""
        words = self._tokenize(text)
        corrected_words = []
        corrections = []
        
        # SÃ©lectionner le bon correcteur
        checker = self.spell_checkers.get(lang, self.spell_checkers.get('en'))
        
        for i, word in enumerate(words):
            # 1. Si le mot est protÃ©gÃ©, on ne touche pas
            if word in self.protected_words:
                 corrected_words.append(word)
                 continue
                 
            # 2. Si le mot est connu (MÃ©dical ou Standard), on le garde
            is_known_med = (self.vocab[word] > 5)
            is_known_std = False
            
            if checker:
                is_known_std = (word in checker)
            
            if is_known_med or is_known_std:
                 corrected_words.append(word)
                 continue
            
            # 3. Mot inconnu -> Correction
            prev_word = corrected_words[-1] if i > 0 else None
            
            candidates = []
            if checker:
                cands = checker.candidates(word)
                if cands:
                    candidates = list(cands)
            
            # Fallback si pyspellchecker Ã©choue ou n'est pas lÃ 
            if not candidates:
                candidates = self._get_candidates(word)
            
            best_candidate = self._choose_best_candidate(candidates, prev_word)
            
            if best_candidate != word:
                corrections.append({'original': word, 'corrected': best_candidate, 'type': 'spelling'})
            
            corrected_words.append(best_candidate)
            
        return ' '.join(corrected_words), corrections

    def _tokenize(self, text: str) -> List[str]:
        return re.findall(r'\w+', text.lower())

    def _get_candidates(self, word: str) -> List[str]:
        """GÃ©nÃ¨re des candidats Ã  distance d'Ã©dition 1 ou 2"""
        letters = 'abcdefghijklmnopqrstuvwxyz'
        splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]
        
        # Distance 1
        deletes = [L + R[1:] for L, R in splits if R]
        transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R) > 1]
        replaces = [L + c + R[1:] for L, R in splits if R for c in letters]
        inserts = [L + c + R for L, R in splits for c in letters]
        
        dist1 = set(deletes + transposes + replaces + inserts)
        
        # Filtrer par vocabulaire connu pour rÃ©duire l'espace
        known_dist1 = [w for w in dist1 if w in self.vocab or w in self.medical_priority]
        if known_dist1:
            return known_dist1
            
        return [word] # Fallback

    def _choose_best_candidate(self, candidates: List[str], prev_word: str) -> str:
        """Choisit le meilleur candidat basÃ© sur la probabilitÃ© Unigram + Bigram"""
        if not candidates:
            return ""
            
        best_word = candidates[0]
        max_score = -1
        
        for cand in candidates:
            # Score Unigram (FrÃ©quence globale)
            unigram_score = self.vocab[cand] / self.total_words if self.total_words > 0 else 0
            
            # Score Bigram (Contexte)
            bigram_score = 0
            if prev_word:
                bigram_count = self.bigrams[(prev_word, cand)]
                prev_count = self.vocab[prev_word]
                if prev_count > 0:
                    bigram_score = bigram_count / prev_count
            
            # Score total (Poids fort sur le contexte et les mots mÃ©dicaux)
            medical_bonus = 100 if cand in self.medical_priority else 1
            
            # Formule: ProbabilitÃ© combinÃ©e * Bonus mÃ©dical
            total_score = (unigram_score + (bigram_score * 50)) * medical_bonus
            
            if total_score > max_score:
                max_score = total_score
                best_word = cand
                
        return best_word

    def _check_contextual_typo(self, word: str, prev_word: str) -> str:
        """DÃ©tecte si un mot valide est improbable dans ce contexte (ex: 'hear' aprÃ¨s 'my')"""
        if not prev_word:
            return None
            
        # Si le bigram actuel n'a jamais Ã©tÃ© vu
        if self.bigrams[(prev_word, word)] == 0:
            # On regarde si une variante proche (dist 1) ferait sens ici
            candidates = self._get_candidates(word)
            for cand in candidates:
                if cand == word: continue
                # Si le candidat est mÃ©dical ou a un fort bigram
                if self.bigrams[(prev_word, cand)] > 0 or cand in self.medical_priority:
                     # On vÃ©rifie si le candidat est nettement plus probable
                     if self.vocab[cand] > 0: # Sanity check
                         return cand
        return None
